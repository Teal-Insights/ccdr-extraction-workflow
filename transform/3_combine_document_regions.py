"""
This script combines individual `document_regions.json` files (generated by `1_extract_images.py`) into a single consolidated JSON file.

Key functionality:
1. Searches for all `document_regions.json` files in subdirectories under `transform/images/dl_*`.
2. Merges the contents of these files into a single array.
3. Writes the combined data to a new file (`transform/images/document_regions.json`).

Output:
- A single JSON file (`document_regions.json`) containing all extracted regions from processed documents.
- Logs the number of files combined and the total number of items in the output.
"""

import json
import glob

def combine_document_regions():
    # Get all document_regions.json files in dl_* directories
    json_files = sorted(glob.glob('transform/images/dl_*/document_regions.json'))
    
    # Combined array to store all JSON data
    combined_data = []
    
    # Read each file and extend the combined array
    for json_file in json_files:
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
                if isinstance(data, list):
                    combined_data.extend(data)
                else:
                    combined_data.append(data)
        except Exception as e:
            print(f"Error processing {json_file}: {e}")
    
    # Write the combined data to a new file
    output_path = 'transform/images/document_regions.json'
    with open(output_path, 'w') as f:
        json.dump(combined_data, f, indent=2)
    
    print(f"Combined {len(json_files)} files into {output_path}")
    print(f"Total number of items: {len(combined_data)}")

if __name__ == "__main__":
    combine_document_regions() 